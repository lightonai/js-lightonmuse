export interface ApiScore {
	/**
	 * The overall log-probability of the entire text processed.
	 */
	logprob: number;

	/**
	 * The same as `logprob`, but normalized for text length (number of tokens).
	 */
	normalized_logprob: number;

	/**
	 * A dictionary including the specific log-probability of each token.
	 */
	token_logprob: null | Record<string, number>;
}

export interface ApiExecutionMetadataCost {
	/**
	 * The number of tokens used.
	 */
	tokens_used: number;

	/**
	 * The number of tokens sent in input to the model.
	 */
	tokens_input: number;

	/**
	 * The number of tokens generated by the model.
	 */
	tokens_generated: number;

	/**
	 * String with the form `model_name@skill`, indicating the nature of the tokens used (if no skills are used, it will be replaced by `default`)
	 */
	cost_type: string;

	/**
	 * The number of requests made in a single batch; and a `finish_reason` entry,
	 * explaining why did the model stopped processing further tokens (`length` if
	 * stopped by `n_tokens` or by reaching the end of the text to process,
	 * or `stop_word` if reached one of the `stop_words`).
	 */
	batch_size: number;
}

/**
 * Explains why the model stopped processing further tokens
 */
export enum ApiFinishReason {
	/**
	 * Stopped by `n_tokens` or by reaching the end of the text to process
	 */
	Length = 'length',

	/**
	 * Reached one of the `stop_words`
	 */
	StopWord = 'stop_word',
}

/**
 * Collects information relevant to the cost and execution of the request.
 * It is available at the top level, as well as for each individual element of a batch.
 */
export interface ApiExecutionMetadata {
	/**
	 * The detailed total cost of the request.
	 */
	cost: ApiExecutionMetadataCost;

	/**
	 * Explains why the model stopped processing further tokens
	 */
	finish_reason: ApiFinishReason;
}

export interface ApiModelCosts {
	total_tokens_used: number;
	total_tokens_input: number;
	total_tokens_generated: number;
	batch_size: number;
}

export interface ApiResponseBase<Output> {
	/**
	 * A unique identifier of the request
	 */
	request_id: string;

	/**
	 * List containing the model answer to your request, and useful metadata.
	 * Has the same form than batching request.
	 */
	outputs: Output[][];

	/**
	 * A record with the name of the model and the number of tokens that was used.
	 */
	costs: Record<string, ApiModelCosts>;
}

export interface ApiResponseBadRequest {
	details: string;
}

export const isApiResponseBadRequest = (
	body: unknown
): body is ApiResponseBadRequest =>
	typeof (body as ApiResponseBadRequest)?.details === 'string';

export interface ApiResponseError {
	request_id: string;
	error_msg: string;
}

export const isApiResponseError = (body: unknown): body is ApiResponseError =>
	typeof (body as ApiResponseError)?.request_id === 'string' &&
	typeof (body as ApiResponseError)?.error_msg === 'string';
